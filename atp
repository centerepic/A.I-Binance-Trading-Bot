# -*- coding: utf-8 -*-
"""
Created on Mon Jul 22 06:58:25 2024

@author: azzy
"""

from keys import *
# importing keys
import pandas as pd
import numpy as np #computing multidimensionla arrays
from datetime import datetime
from time import sleep
from binance.client import Client
from binance import *
from binance.enums import *
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
import joblib
import os
from scipy.integrate import trapezoid
globalInterval=Client.KLINE_INTERVAL_15MINUTE
########close/open trades###########
def Lsafe(client,Seed,mrgType,lvrg):
    try:
        client.futures_change_leverage(symbol=Seed,leverage=lvrg)
        client.futures_change_margin_type(symbol=Seed,marginType=mrgType)
    except:
        return
    
#Precession
def get_current_datetime_as_string():
    current_datetime = datetime.now()
    return current_datetime.strftime("%Y-%m-%d %H:%M:%S")

def truncate(number, precision):
    factor = 10.0 ** precision
    return int(number * factor) / factor

def LongOrder(client, Seed, precision, numBots, lvrg):
    balance = client.futures_account_balance()
    bal = None
    
    for wc in balance:
        if wc["asset"] == 'USDT':
            bal = float(wc["balance"])
            break

    if bal is None:
        return "No USDT balance found"

    percent = 0.9 / numBots  # Calculate the percentage of balance to use for each bot

    price = float(client.futures_mark_price(symbol=Seed)["markPrice"])
    maxl = (bal * percent) * lvrg
    maxq = maxl / price
    q = truncate(maxq, precision)

    try:
        result=client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_BUY, quantity=str(q))
        if result['orderId']:
            return str(q)
        else:
            return 'null'
    except Exception as e:
        print("ShortOrder",e)
        return 'null'
    
def ShortOrder(client, Seed, precision, numBots, lvrg):
    balance = client.futures_account_balance()
    bal = None
    
    for wc in balance:
        if wc["asset"] == 'USDT':
            bal = float(wc["balance"])
            break

    if bal is None:
        return "No USDT balance found"

    percent = 0.9 / numBots  # Calculate the percentage of balance to use for each bot

    price = float(client.futures_mark_price(symbol=Seed)["markPrice"])
    maxl = (bal * percent) * lvrg
    maxq = maxl / price
    q = truncate(maxq, precision)

    try:
        result=client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_SELL, quantity=str(q))
        if result['orderId']:
            return str(q)
        else:
            return 'null'
    except Exception as e:
        print("ShortOrder",e)
        return 'null'
        

def closeLong(client, p, Seed):
    try:
        client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_SELL, quantity=p, reduceOnly='true')
        return f"Closed long position with quantity {p}"
    except:
        return 'null'

def closeShort(client, p, Seed):
    try:
        client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_BUY, quantity=p, reduceOnly='true')
        return f"Closed short position with quantity {p}"
    except:
        return 'null'
    
def TradeLog():
    if not os.path.exists('TradeLog.csv'):
        # Create a DataFrame with the desired structure
        data = {
            'token': [],
            'datetime': [],
            'opprice': [],
            'result':[],
            'status': []
        }
        df = pd.DataFrame(data)
        df.to_csv('TradeLog.csv', index=False)
        return df
    else:
        df=pd.read_csv('TradeLog.csv')
        return df

def clear_tradeLog():
    try:
        os.remove("TradeLog.csv")
        print(" TradeLog.csv deleted successfully.")
    except FileNotFoundError:
        print("File TradeLog.csv not found.")
        pass
    except Exception as e:
        print(f"An error occurred: {e}")

def add_tradeLog(Ti,datetime, opprice,result,amount,status):
    dataframe=TradeLog()
    new_row = pd.DataFrame({
        'token': Ti,
        'datetime': datetime,
        'opprice': opprice,
        'amount': amount,
        'result': result,
        'status': status
    }, index=[0])  # Ensure it's a single row DataFrame
    
    dataframe = pd.concat([dataframe, new_row], ignore_index=True)
    dataframe.to_csv('TradeLog.csv', index=False)
    
def update_cell_Tlog(token, column_name, new_value):
    df=TradeLog()
    row_index = df.index[df['token'] == token ].tolist()
    if not row_index:
        print(f"Indicator '{token}' not found.")
        return
    column_index = df.columns.get_loc(column_name)
    df.iloc[row_index[0], column_index] = new_value
    df.to_csv('TradeLog.csv', index=False)
    return True

def read_matching_TLog(token, column_name):
    df=TradeLog()
    row_index = df.index[df['token'] == token].tolist()
    if not row_index:
        print(f"Indicator '{token}' not found.")
        return
    column_index = df.columns.get_loc(column_name)
    cell_value = df.iloc[row_index[0], column_index]
    return cell_value

#############################################################
# Initialize models
mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, warm_start=True)
mlp_predictor = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, warm_start=True)

# Initialize a scaler for the input data
scaler = StandardScaler()

# Initialize memory to hold the training data
memory = {
    'X': [],
    'y_detection': [],
    'y_prediction': []
}

def train_market(areas, significant_threshold=1.0, model_file="models/market_model.pkl"):
    # Create the directory if it does not exist
    os.makedirs(os.path.dirname(model_file), exist_ok=True)

    # Preprocess the data
    X = np.array(areas).reshape(-1, 1)  # Input features
    X_scaled = scaler.fit_transform(X)

    # Prepare labels for detection (whether the last area is large or not)
    y_detection = np.array([1 if abs(area) >= significant_threshold else 0 for area in areas])
    
    # Prepare labels for prediction (whether the current curve will become large)
    y_prediction = np.roll(y_detection, -1)  # Shift the detection labels to align with the current curve
    y_prediction[-1] = 0  # No prediction for the last area, but this won't affect training

    # Store the data for incremental learning
    memory['X'].append(X_scaled)
    memory['y_detection'].append(y_detection)
    memory['y_prediction'].append(y_prediction)

    # Convert lists to arrays
    X_memory = np.vstack(memory['X'])
    y_detection_memory = np.concatenate(memory['y_detection'])
    y_prediction_memory = np.concatenate(memory['y_prediction'])

    # Incremental fit to the models
    mlp_classifier.partial_fit(X_memory, y_detection_memory, classes=[0, 1])
    mlp_predictor.partial_fit(X_memory, y_prediction_memory, classes=[0, 1])

    # Save the models
    joblib.dump((mlp_classifier, mlp_predictor, scaler), model_file)

def detect_and_predict(areas, model_file="models/market_model.pkl"):
    # Load the models
    mlp_classifier, mlp_predictor, scaler = joblib.load(model_file)

    # Prepare the data
    X = np.array(areas).reshape(-1, 1)

    # Scale the data
    X_scaled = scaler.transform(X)

    # Detection: Probability that the last area is large
    last_area = X_scaled[-1].reshape(1, -1)
    detection_proba = mlp_classifier.predict_proba(last_area)[0, 1]

    # Prediction: Probability that the current curve will become large
    prediction_proba = mlp_predictor.predict_proba(last_area)[0, 1]

    # Subtract detection_proba from prediction_proba to form the confidence score
    combined_confidence = prediction_proba - detection_proba

    # Ensure the confidence score is within a reasonable range [0, 1] after subtraction
    combined_confidence = max(min(combined_confidence, 1), 0)

    # Calculate the slope between the last two areas
    if len(areas) > 1:
        slope = areas[-1] - areas[-2]
        
        # If the slope is negative (indicating a peak), reduce confidence
        if slope < 0:
            reduction_factor = 1 + (abs(slope) / max(abs(areas[-2]), 1e-6))  # Dynamic reduction based on slope
            combined_confidence /= reduction_factor

    # **New Addition: Volatility Check**
    if len(areas) > 3:
        volatility = np.std(areas[-4:])
        if volatility < 0.1:  # Adjust this threshold based on your data
            combined_confidence *= 0.5  # Reduce confidence in low volatility conditions
    
    # Scale the confidence score to a range of 0 to 10
    confidence_score = round(combined_confidence * 10, 1)

    # Determine direction from the last element in areas
    direction = 1 if areas[-1] > 0 else 0

    return confidence_score, direction

def get_average_confidence(global_confidence_values):
    return sum(global_confidence_values) / len(global_confidence_values) if global_confidence_values else 0

#################### Get token info #########################

def batchCollector(excludedlist,CurrencyType):
    client = Client(api_key, api_secret)
    exInfo=client.futures_exchange_info()
    tokenInf,sinf=FindNewToken(client,exInfo,CurrencyType)
    Ftoken_list,global_confidence=OpenLayer(excludedlist,tokenInf)
    return Ftoken_list,sinf,global_confidence

def FindNewToken(client,exInfo,CurrencyType):
    symInfo={}
    tokenInfo={}
    for symbol in exInfo["symbols"]:
        if symbol["contractType"]=="PERPETUAL" and CurrencyType in symbol["symbol"] and symbol["status"]=="TRADING":
            symInfo[symbol["symbol"]]=symbol["quantityPrecision"]
    x=0
    for key,values in symInfo.items():
        try:
            candles = client.futures_continous_klines(pair=key, interval=globalInterval,ContractType='PERPETUAL')
            df = pd.DataFrame(candles)
            df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
            df['timestart'] = df['timestart'] / 1000
            df['timeend'] = df['timeend'] / 1000
            df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
            tokenInfo[key]=df
            if x==30:
                print("30%")
            if x==80:
                print("55%")
            if x==130:
                print("69%")
            x+=1           
        except Exception as e:
            #TokenInfo error Removed from Market or not added yet
            print("TokenInfo error Removed from Market or not added yet",key,e)
            continue
    return tokenInfo,symInfo

def OpenLayer(excludedlist,TokenInfo):
    
    ranked_result = {}
    print("90% Training and detecting")
    
    # First loop: Training
    for Ti, df in TokenInfo.items():
        try:
            cmf_series=CMF(df)
            rsi_series=rsi(df)
            macd_series=MACD(df)
            adx_series=ADX(df)
            data = normalize((cmf_series + rsi_series + macd_series + adx_series) / 4)
            smoothed_series = moving_average(data, window=14)     
            areas = calculate_areas(smoothed_series)
            # Check for NaN values in areas
            if np.isnan(areas).any():
                continue  # Skip this token and move to the next one
            train_market(areas)
        except Exception as e:
            print(f"TRAINMARKET error: {str(e)}")
            continue
    global_confidence_values=[]
    # Second loop: Prediction
    for Ti, df in TokenInfo.items():
        try:
            if Ti not in excludedlist:
                cmf_series=CMF(df)
                rsi_series=rsi(df)
                macd_series=MACD(df)
                adx_series=ADX(df)
                data = normalize((cmf_series + rsi_series + macd_series + adx_series) / 4)
                smoothed_series = moving_average(data, window=14)     
                areas = calculate_areas(smoothed_series)
                if np.isnan(areas).any():
                    continue  # Skip this token and move to the next one
                confidence_score, direction = detect_and_predict(areas)
                global_confidence_values.append(confidence_score)
                if direction == 1:
                    ranked_result[Ti] = [confidence_score, 'FL']
                else:
                    ranked_result[Ti] = [confidence_score, 'FS']  
        except Exception as e:
            print(f"predictloop error: {str(e)}")
            continue

    # Sort the keys based on the first element of the list in descending order
    sorted_keys = sorted(ranked_result.keys(), key=lambda x: ranked_result[x][0], reverse=True)
    # Reorganize the dictionary using the sorted keys
    sorted_ranked_result = {key: ranked_result[key] for key in sorted_keys}
    global_confidence_value=round(get_average_confidence(global_confidence_values),1)
    print("100%")
    return sorted_ranked_result,global_confidence_value

#################### Get token info #########################

############# Indicators #############
def CMF(df, period=14):
    mf = ((df['close'] - df['low']) - (df['high'] - df['close'])) / (df['high'] - df['low'])
    mfv = mf * df['volume']
    cmf = mfv.rolling(period).sum() / df['volume'].rolling(period).sum()
    # Forward fill and backward fill
    cmf = cmf.ffill().bfill()
    return cmf

def rsi(df, period=14):
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=period, min_periods=1).mean()
    avg_loss = loss.rolling(window=period, min_periods=1).mean()
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    # Forward fill and backward fill
    rsi = rsi.ffill().bfill()
    return rsi

def MACD(df, short_period=12, long_period=26, signal_period=9):
    short_ema = df['close'].ewm(span=short_period, adjust=False).mean()
    long_ema = df['close'].ewm(span=long_period, adjust=False).mean()
    macd_line = short_ema - long_ema
    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()
    macd_histogram = macd_line - signal_line
    # Forward fill and backward fill
    macd_histogram = macd_histogram.ffill().bfill()
    return macd_histogram

def ADX(df, period=14):
    high = df['high']
    low = df['low']
    close = df['close']
    
    plus_dm = high.diff()
    minus_dm = low.diff()
    
    plus_dm = plus_dm.where((plus_dm > minus_dm) & (plus_dm > 0), 0)
    minus_dm = minus_dm.where((minus_dm > plus_dm) & (minus_dm > 0), 0)
    
    tr = pd.concat([high - low, abs(high - close.shift()), abs(low - close.shift())], axis=1).max(axis=1)
    atr = tr.rolling(window=period).mean()
    
    plus_di = 100 * (plus_dm.rolling(window=period).mean() / atr)
    minus_di = 100 * (minus_dm.rolling(window=period).mean() / atr)
    
    dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100
    adx = dx.rolling(window=period).mean()
    
    # Forward fill and backward fill
    adx = adx.ffill().bfill()
    return adx

def z_score(series):
    return (series - series.mean()) / series.std()

def moving_average(series, window=14):
    return series.rolling(window=window, min_periods=1).mean()
def calculate_areas(series):
    areas = []
    segment_start = 0

    for i in range(1, len(series)):
        if series.iloc[i] > series.iloc[i-1]:
            # Rising segment
            if segment_start != i - 1 and series.iloc[i-1] < series.iloc[segment_start]:
                # If previous segment was falling, close it
                segment = series.iloc[segment_start:i]
                area = trapezoid(segment)
                areas.append(round(-abs(area), 3))  # Negative area for falling segment, rounded to 3 decimal places
                segment_start = i - 1

        elif series.iloc[i] < series.iloc[i-1]:
            # Falling segment
            if segment_start != i - 1 and series.iloc[i-1] > series.iloc[segment_start]:
                # If previous segment was rising, close it
                segment = series.iloc[segment_start:i]
                area = trapezoid(segment)
                areas.append(round(area, 3))  # Positive area for rising segment, rounded to 3 decimal places
                segment_start = i - 1

    # Handle the last segment
    if segment_start < len(series) - 1:
        segment = series.iloc[segment_start:]
        area = trapezoid(segment)
        if series.iloc[-1] > series.iloc[segment_start]:
            areas.append(round(area, 3))
        else:
            areas.append(round(-abs(area), 3))

    return areas

def normalize(series):
    min_val = series.min()
    max_val = series.max()
    normalized_series = 2 * (series - min_val) / (max_val - min_val) - 1
    return normalized_series
def all_w_or_l(column_name, df):
    # Check if the column exists in the DataFrame
    if column_name not in df.columns:
        raise ValueError(f"Column '{column_name}' does not exist in the DataFrame.")
    
    # Check if all values in the column are either 'W' or 'L'
    if (df[column_name].isin(['W', 'L'])).all():
        return True
    else:
        return False
    
############# Indicators #############    
########close/open trades########### add_tradeLog(Ti,datetime, opprice,result,amount,status,EXP)
def Rtrade(bList,BotLimit,lvrg,tinfo,mode,global_confidence):
    client = Client(api_key, api_secret)
    mrgType="ISOLATED"
    x=0
    for Ti,ttype in bList.items():
        Lsafe(client, Ti, mrgType, lvrg)
        candles = client.futures_continous_klines(pair=Ti, interval=globalInterval,ContractType='PERPETUAL')
        df = pd.DataFrame(candles)
        df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
        df['timestart'] = df['timestart'] / 1000
        df['timeend'] = df['timeend'] / 1000
        df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
        if ttype[1]=="FL":
            opprice = df['close'].iloc[-1]
            datetime=get_current_datetime_as_string()
            if mode=='R':
                p=LongOrder(client,Ti,tinfo[Ti],BotLimit,lvrg)
                if p!="null" and p!='':    
                    print("added:",Ti,ttype)
                    add_tradeLog(Ti,datetime,opprice,'A',p,ttype[1])
                    x+=1
            else:
                print("added:",Ti,ttype)
                add_tradeLog(Ti,datetime,opprice,'A','nan',ttype[1])
                x+=1
        if  ttype[1]=="FS":
            opprice = df['close'].iloc[-1]
            datetime=get_current_datetime_as_string()
            if mode=='R':
                p=ShortOrder(client,Ti,tinfo[Ti],BotLimit,lvrg)
                if p!="null" and p!='':
                    print("added:",Ti,ttype)
                    add_tradeLog(Ti,datetime,opprice,'A',p,ttype[1])
                    x+=1
            else:
                print("added:",Ti,ttype)
                add_tradeLog(Ti,datetime,opprice,'A','nan',ttype[1])
                x+=1
        if x>=BotLimit:
            break
        sleep(5)
    while True:
        TLog=TradeLog()
        for x in range(len(TLog)):
            status=TLog.iloc[x]['status']
            svresult=TLog.iloc[x]['result']
            Ti=TLog.iloc[x]['token']
            amount=read_matching_TLog(Ti, 'amount')
            oprice=read_matching_TLog(Ti, 'opprice')
            if svresult!='W' and svresult!='L':
                candles = client.futures_continous_klines(pair=Ti, interval=globalInterval,ContractType='PERPETUAL')
                df = pd.DataFrame(candles)
                df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
                df['timestart'] = df['timestart'] / 1000
                df['timeend'] = df['timeend'] / 1000
                df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
                cmf_series=CMF(df)
                rsi_series=rsi(df)
                macd_series=MACD(df)
                adx_series=ADX(df)
                cprice = df['close'].iloc[-1]
                data = normalize((cmf_series + rsi_series + macd_series + adx_series) / 4)
                smoothed_series = moving_average(data, window=14)     
                areas = calculate_areas(smoothed_series)
                train_market(areas)
                confidence_score, direction = detect_and_predict(areas)
                #print(Ti,confidence_score,direction)
                if status=='FS' and confidence_score>global_confidence and direction==1:
                    if oprice>cprice:
                        if mode=='R':
                            closeShort(client,amount,Ti)
                        update_cell_Tlog(Ti, 'result', 'W')
                        print("trade closed : ", Ti,oprice,cprice, 'W')
                        break
                    else:
                        if mode=='R':
                            closeShort(client,amount,Ti)
                        update_cell_Tlog(Ti, 'result', 'L')
                        print("trade closed : ", Ti,oprice,cprice, 'L')
                        break        
                if status=='FL' and confidence_score>global_confidence and direction==0:
                    if oprice<cprice:
                        if mode=='R':
                            closeLong(client,amount,Ti)
                        update_cell_Tlog(Ti, 'result', 'W')
                        print("trade closed : ", Ti,oprice,cprice, 'W')
                        break
                    else:
                        if mode=='R':
                            closeLong(client,amount,Ti)
                        update_cell_Tlog(Ti, 'result', 'L')
                        print("trade closed : ",Ti,oprice,cprice, 'L')
                        break        
        TLog=TradeLog()
        if all_w_or_l('result', TLog):
            print("All Trades Done")
            return True
        sleep(300)
    print("All Trades Done")
    return True
########trainer############
def MAIN_TRADER(excludedlist,CurrencyType,BotLimit,lvrg,initial,mode):
    client = Client(api_key, api_secret)
    while True:
        balance = client.futures_account_balance()
        bal = None
        for wc in balance:
            if wc["asset"] == 'USDT':
                bal = float(wc["balance"])
        if bal > initial:
            amnt = bal - initial
            client.futures_account_transfer(asset='USDT', amount=amnt, Type=2)
            print("Profit Transfer:", amnt)
        if bal > 100:
            BotLimit=4
        if bal > 500:
            BotLimit=8
        if bal > 900:
            BotLimit=10
        TokenList,tinfo,global_confidence = batchCollector(excludedlist,CurrencyType)
        print('tokens found:',len(TokenList))
        print('global confidence:',global_confidence)
        #break
        if len(TokenList)>0:
            Rtrade(TokenList,BotLimit,lvrg,tinfo,mode,global_confidence)
        clear_tradeLog()
        print("sleeping waiting for next cycle")
clear_tradeLog()
BotLimit=2
mode='R'
print("Booting up... ")
excludedlist=['BTCUSDT','BTCDOMUSDT','USDCUSDT','ETHUSDT','XEMUSDT']
CurrencyType="USDT"
lvrg=2
initial_amt=1000
MAIN_TRADER(excludedlist,CurrencyType,BotLimit,lvrg,initial_amt,mode)
