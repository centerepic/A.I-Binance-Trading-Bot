# -*- coding: utf-8 -*-
"""
Created on Mon Jan  8 06:16:20 2024

@author: azzy
"""
from keys import *
# importing keys
import multiprocessing
import pandas as pd
import numpy as np #computing multidimensionla arrays
from datetime import datetime
from time import sleep
from binance.client import Client
from binance import *
from binance.enums import *
import math
import pandas_ta as ta
import operator
import os
import sys
import ast
globalInterval=Client.KLINE_INTERVAL_5MINUTE
########close/open trades###########
def Lsafe(client,Seed,mrgType,lvrg):
    try:
        client.futures_change_leverage(symbol=Seed,leverage=lvrg)
        client.futures_change_margin_type(symbol=Seed,marginType=mrgType)
    except:
        return
    
#Precession
def get_current_datetime_as_string():
    current_datetime = datetime.now()
    return current_datetime.strftime("%Y-%m-%d %H:%M:%S")

def truncate(f, n):
    return round(f,n)
#Order System
def LongOrder(client,Seed,precision,percent,lvrg):
    balance = client.futures_account_balance()
    bal=None
    for wc in balance:
        if wc["asset"]=='USDT':
            bal=float(wc["balance"])
    price = client.futures_mark_price(symbol=Seed)["markPrice"]
    maxl=(bal*percent) * lvrg
    maxq=maxl/ float(price)
    q=truncate(maxq,precision)
    try:
        client.futures_create_order(symbol=Seed,type=ORDER_TYPE_MARKET,side=SIDE_BUY,quantity=str(q))
        return str(q)
    except:
        return "null"
    
def ShortOrder(client,Seed,precision,percent,lvrg):
    balance = client.futures_account_balance()
    bal=None
    for wc in balance:
        if wc["asset"]=='USDT':
            bal=float(wc["balance"])
    price = client.futures_mark_price(symbol=Seed)["markPrice"]
    maxl=(bal*percent) * lvrg
    maxq=maxl/ float(price)
    q=truncate(maxq,precision)
    try:
        client.futures_create_order(symbol=Seed,type=ORDER_TYPE_MARKET,side=SIDE_SELL,quantity=str(q))
        return str(q)
    except:
        return "null"

def closeLong(p,Seed):
    try:
        client.futures_create_order(symbol=Seed,type=ORDER_TYPE_MARKET,side=SIDE_SELL,quantity=p,reduceOnly='true')
    except Exception as e:
        print("exception order Error",e)
        
def closeShort(p,Seed):
    try:
        client.futures_create_order(symbol=Seed,type=ORDER_TYPE_MARKET,side=SIDE_BUY,quantity=p,reduceOnly='true')
    except Exception as e:
        print("exception order Error",e)
########close/open trades###########

#################### Get token info #########################

def batchCollector(excludedlist,CurrencyType):
    client = Client(api_key, api_secret)
    exInfo=client.futures_exchange_info()
    tokenInf,sinf=FindNewToken(client,exInfo,excludedlist,CurrencyType)
    Ftoken_list=OpenLayer(tokenInf)
    return Ftoken_list

def TokenInfo(client,sym,CurrencyType):
    try:
        candles = client.futures_continous_klines(pair=sym, interval=globalInterval,ContractType='PERPETUAL')
        df = pd.DataFrame(candles)
        df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
        df['timestart'] = df['timestart'] / 1000
        df['timeend'] = df['timeend'] / 1000
        df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
        return df
    except Exception as e:
        #TokenInfo error Removed from Market or not added yet
        print("TokenInfo error Removed from Market or not added yet",e)

def FindNewToken(client,exInfo,excludedlist,CurrencyType):
    symInfo={}
    tokenInfo={}
    for symbol in exInfo["symbols"]:
        if symbol["contractType"]=="PERPETUAL" and symbol["symbol"] not in excludedlist and CurrencyType in symbol["symbol"] and symbol["status"]=="TRADING":
            symInfo[symbol["symbol"]]=symbol["quantityPrecision"]
    x=0
    for key,values in symInfo.items():
        result=TokenInfo(client,key,CurrencyType)
        tokenInfo[key]=result
        if x==30:
            print("30%")
        if x==80:
            print("80%")
        if x==130:
            print("99%")
        x+=1
    print('100%')            
    return tokenInfo,symInfo

def OpenLayer(TokenInfo):
    ranked_result={}
    trade_types=['GL','GS','TL','TS']
    for Ti,value in TokenInfo.items():
        pressurelist={}
        try:
            TZSCORE=zscore(value)
            TCMF=CMF(value)
            TTREND=super_trend(value)
            TRSI=rsi(value)
            for ttype in trade_types:
                range_rsi=ast.literal_eval(read_matching_table('nodes','RSI', ttype))[0]
                range_cmf=ast.literal_eval(read_matching_table('nodes','CMF', ttype))[0]
                trend=ast.literal_eval(read_matching_table('nodes','TREND', ttype))[0]
                range_zscore=ast.literal_eval(read_matching_table('nodes','ZSCORE', ttype))[0]
                range_intensity=is_between(range_rsi,TRSI,range_cmf,TCMF,range_zscore,TZSCORE,TTREND,trend,ttype)
                pressurelist[ttype]=round((range_intensity+TZSCORE),2)
        except Exception as e:
            #TokenInfo error Removed from Market or not added yet
            print("TokenInfo error Removed from Market or not added yet",e) 
        print(pressurelist)
        bestchoice=get_key_of_higher_number(pressurelist)
        bias=float(read_matching_table('weights','bias', bestchoice))
        if pressurelist[bestchoice]>bias:
            ranked_result[Ti]=[pressurelist[bestchoice],bestchoice]
    # Sort the keys based on the first element of the list in descending order
    sorted_keys = sorted(ranked_result.keys(), key=lambda x: ranked_result[x][0], reverse=True)
    # Reorganize the dictionary using the sorted keys
    sorted_ranked_result = {key: ranked_result[key] for key in sorted_keys}
    Tresult={}
    for key,item in sorted_ranked_result.items():
        Tresult[key]=item[1]
    return Tresult

def get_key_of_higher_number(dictionary):
    # Initialize variables to keep track of the highest number and its corresponding key
    highest_number = float('-inf')  # Start with a very low number
    highest_key = None

    # Iterate through the dictionary
    for key, value in dictionary.items():
        # If the current value is higher than the highest number found so far
        if value > highest_number:
            highest_number = value
            highest_key = key
    # Return the key corresponding to the highest number
    return highest_key

def get_key_of_lower_number(dictionary):
    # Initialize variables to keep track of the lowest number and its corresponding key
    lowest_number = float('inf')  # Start with a very high number
    lowest_key = None

    # Iterate through the dictionary
    for key, value in dictionary.items():
        # If the current value is lower than the lowest number found so far
        if value < lowest_number:
            lowest_number = value
            lowest_key = key
    # Return the key corresponding to the lowest number
    return lowest_key

def find_largest_number(pressurelist):
    # Initialize the maximum value to the smallest possible integer
    max_value = float('-inf')

    # Iterate through the dictionary
    for value in pressurelist.values():
        # Update the maximum value if the current value is greater
        if value > max_value:
            max_value = value

    return max_value
def CloseLayer(TRSI,TCMF,TTREND,TZSCORE,ttype):
    range_rsi=ast.literal_eval(read_matching_table('nodes','RSI', ttype))[1]
    range_cmf=ast.literal_eval(read_matching_table('nodes','CMF', ttype))[1]
    trend=ast.literal_eval(read_matching_table('nodes','TREND', ttype))[1]
    range_zscore=ast.literal_eval(read_matching_table('nodes','ZSCORE', ttype))[1]
    bias=float(read_matching_table('weights','bias', ttype))
    edge_intensity=is_close(range_rsi,TRSI,range_cmf,TCMF,range_zscore,TZSCORE,TTREND,trend,ttype)
    if edge_intensity>bias:
        return True
    else:
        return False

def is_close(range_rsi,TRSI,range_cmf,TCMF,range_zscore,TZSCORE,TTREND,trend,ttype):
    RSI_intensity= intensity_from_edge(TRSI, range_rsi[0], range_rsi[1])
    CMF_intensity= intensity_from_edge(TCMF, range_cmf[0], range_cmf[1])
    ZSCORE_intensity= intensity_from_edge(TZSCORE, range_zscore[0], range_zscore[1])
    if trend==TTREND:
        trend_w=ast.literal_eval(read_matching_table('weights','TREND', ttype))[0]
        cmf_w=ast.literal_eval(read_matching_table('weights','CMF', ttype))[0]
        zscore_w=ast.literal_eval(read_matching_table('weights','ZSCORE', ttype))[0]
        rsi_w=ast.literal_eval(read_matching_table('weights','RSI', ttype))[0]
        average = round(((RSI_intensity*rsi_w) + (CMF_intensity*cmf_w) + (ZSCORE_intensity*zscore_w) + trend_w),3)
    else:
        return 0
    return average
    

def is_between(range_rsi,TRSI,range_cmf,TCMF,range_zscore,TZSCORE,TTREND,trend,ttype):
    RSI_intensity= intensity_from_mid(TRSI, range_rsi[0], range_rsi[1])
    CMF_intensity= intensity_from_mid(TCMF, range_cmf[0], range_cmf[1])
    ZSCORE_intensity= intensity_from_mid(TZSCORE, range_zscore[0], range_zscore[1])
    if trend==TTREND:
        trend_w=ast.literal_eval(read_matching_table('weights','TREND', ttype))[0]
        cmf_w=ast.literal_eval(read_matching_table('weights','CMF', ttype))[0]
        zscore_w=ast.literal_eval(read_matching_table('weights','ZSCORE', ttype))[0]
        rsi_w=ast.literal_eval(read_matching_table('weights','RSI', ttype))[0]
        average = round(((RSI_intensity*rsi_w) + (CMF_intensity*cmf_w) + (ZSCORE_intensity*zscore_w) + trend_w),3)
    else:
        return 0
    return average


#################### Get token info #########################

############# Indicators #############
def super_trend(df, period=7, multiplier=3.0):
    supertrend = df.ta.supertrend(high='high', low='low', close='close', length=period, multiplier=multiplier)
    df = pd.concat([df, supertrend], axis=1)
    latest_trend = 1 if df.iloc[-1]['close'] > df.iloc[-1]['SUPERT_'+str(period)+"_"+str(multiplier)] else 0
    return latest_trend

def CMF(data):
    period = 20
    mf = ((data['close'] - data['low']) - (data['high'] - data['close'])) / (data['high'] - data['low'])
    mfv = mf * data['volume']
    cmf_values = mfv.rolling(period).sum() / data['volume'].rolling(period).sum()
    return round(cmf_values.iloc[-1],3)

def rsi(dataset):
    S=dataset.ta.rsi(length=14)
    rssi=round(S.iloc[-1],1)
    return rssi

def zscore(dataset):
    zpoints=dataset.ta.zscore().dropna()
    zscore=round(zpoints.iloc[-1],3)
    return zscore


def intensity_from_edge(number, range_start, range_end):
    # Sort the range automatically
    sorted_range = sorted([range_start, range_end])
    range_start, range_end = sorted_range[0], sorted_range[1]

    if range_start == range_end:
        raise ValueError("Range start and end cannot be the same.")
    
    if not (range_start <= number <= range_end):
        return 0  # If the number is out of the specified range, intensity is 0.

    # Calculate the midpoint of the range
    midpoint = (range_start + range_end) / 2

    # Calculate the distance of the number from the midpoint
    distance_from_midpoint = abs(number - midpoint)

    # Calculate the maximum distance from the midpoint (half the absolute range)
    max_distance = abs(range_end - range_start) / 2

    # Calculate the intensity based on the distance from the midpoint
    # Adjust the calculation to give a higher intensity when further away from the midpoint
    intensity = 1 - (distance_from_midpoint / max_distance)
    # Change the intensity to be higher when closer to the midpoint
    intensity = 1 - intensity

    return intensity

def same_side_check(num1, num2, range_start, range_end):
    # Sort the range automatically
    sorted_range = sorted([range_start, range_end])
    range_start, range_end = sorted_range[0], sorted_range[1]

    # Calculate the midpoint of the range
    midpoint = (range_start + range_end) / 2

    # Ensure num1 is above the midpoint and num2 is below
    if num1 < midpoint:
        num1, num2 = num2, num1

    # Check if both num1 and num2 are above or below the midpoint
    both_above = num1 > midpoint and num2 > midpoint
    both_below = num1 < midpoint and num2 < midpoint
    return both_above or both_below

def intensity_from_mid(number, range_start, range_end):
    # Sort the range automatically
    sorted_range = sorted([range_start, range_end])
    range_start, range_end = sorted_range[0], sorted_range[1]

    if range_start == range_end:
        raise ValueError("Range start and end cannot be the same.")
    
    if not (range_start <= number <= range_end):
        return 0  # If the number is out of the specified range, intensity is 0.

    # Calculate the midpoint of the range
    midpoint = (range_start + range_end) / 2

    # Calculate the distance of the number from the midpoint
    distance_from_midpoint = abs(number - midpoint)

    # Calculate the maximum distance from the midpoint (half the absolute range)
    max_distance = abs(range_end - range_start) / 2

    # Calculate the intensity based on the distance from the midpoint
    intensity = 1 - (distance_from_midpoint / max_distance)

    return intensity

############# Indicators #############
########################database##############

def nodes():
    if not os.path.exists('nodes.csv'):
        # Create a DataFrame with the desired structure
        data = {
            'IND': ['RSI', 'CMF', 'ZSCORE', 'TREND'],
            'GL': ['[[30,35],[65,70]]', '[[-0.2,0],[0,0.2]]', '[[-1.5,-1],[1,1.5]]', '[0,1]'],
            'GS': ['[[65,70],[30,35]]', '[[0,0.2],[-0.2,0]]', '[[1,1.5],[-1.5,-1]]', '[1,0]'],
            'TL': ['[[70,75],[30,25]]', '[[0.2,0.5],[-0.5,-0.2]]', '[[1.5,2],[-2,-1.5]]', '[1,0]'],
            'TS': ['[[30,25],[70,75]]', '[[-0.5,-0.2],[0.2,0.5]]', '[[-2,-1.5],[1.5,2]]', '[0,1]']
            }
        df = pd.DataFrame(data)
        df.to_csv('nodes.csv', index=False)
        return df
    else:
        df=pd.read_csv('nodes.csv')
        return df
def reflections():
    if not os.path.exists('reflections.csv'):
        # Create a DataFrame with the desired structure
        data = {
            'IND': ['RSI', 'CMF', 'ZSCORE', 'TREND','TNUM'],
            'GL': ['[0,0]', '[0,0]', '[0,0]', '[0,0]','0'],
            'GS': ['[0,0]', '[0,0]', '[0,0]', '[0,0]','0'],
            'TL': ['[0,0]', '[0,0]', '[0,0]', '[0,0]','0'],
            'TS': ['[0,0]', '[0,0]', '[0,0]', '[0,0]','0']
            }
        df = pd.DataFrame(data)
        df.to_csv('reflections.csv', index=False)
        return df
    else:
        df=pd.read_csv('reflection.csv')
        return df
def weights():
    if not os.path.exists('weights.csv'):
        # Create a DataFrame with the desired structure '[1,1]', '[1,1]', '[1,1]', '[1,1]',
        data = {
            'IND': ['RSI', 'CMF', 'ZSCORE', 'TREND','bias'],
            'GL': ['[1,1]', '[1,1]', '[1,1]', '[0,0]','0.5'],
            'GS': ['[1,1]', '[1,1]', '[1,1]', '[0,0]','0.5'],
            'TL': ['[1,1]', '[1,1]', '[1,1]', '[0,0]', '0.5'],
            'TS': ['[1,1]', '[1,1]', '[1,1]', '[0,0]','0.5']
            }
        df = pd.DataFrame(data)
        df.to_csv('weights.csv', index=False)
        return df
    else:
        df=pd.read_csv('weights.csv')
        return df
    
def read_matching_table(table,indicator, column_name):
    if table=='nodes':   
        df=nodes()
        row_index = df.index[df['IND'] == indicator].tolist()
        if not row_index:
            print(f"Indicator '{indicator}' not found.")
            return
        column_index = df.columns.get_loc(column_name)
        cell_value = df.iloc[row_index[0], column_index]
        return cell_value
    if table=='weights':
        df=weights()
        row_index = df.index[df['IND'] == indicator].tolist()
        if not row_index:
            print(f"Indicator '{indicator}' not found.")
            return
        column_index = df.columns.get_loc(column_name)
        cell_value = df.iloc[row_index[0], column_index]
        return cell_value


def update_cell_table(table,indicator, column_name, new_value):
    if table=='nodes':
        df=nodes()
        row_index = df.index[df['IND'] == indicator].tolist()
        if not row_index:
            print(f"Indicator '{indicator}' not found.")
            return
        column_index = df.columns.get_loc(column_name)
        df.iloc[row_index[0], column_index] = new_value
        df.to_csv('nodes.csv', index=False)
        return True
    if table=='weights':
        df=weights()
        row_index = df.index[df['IND'] == indicator].tolist()
        if not row_index:
            print(f"Indicator '{indicator}' not found.")
            return
        column_index = df.columns.get_loc(column_name)
        df.iloc[row_index[0], column_index] = new_value
        df.to_csv('weights.csv', index=False)
        return True
    if table=='reflections':
        df=weights()
        row_index = df.index[df['IND'] == indicator].tolist()
        if not row_index:
            print(f"Indicator '{indicator}' not found.")
            return
        column_index = df.columns.get_loc(column_name)
        df.iloc[row_index[0], column_index] = new_value
        df.to_csv('reflections.csv', index=False)
        return True

def multiTokenHistory():
    if not os.path.exists('multiTokenHistory.csv'):
        # Create a DataFrame with the desired structure
        data = {
            'token': [],
            'price': [],
            'CMF': [],
            'RSI': [],
            'Zscore': [],
            'TREND': []
        }
        df = pd.DataFrame(data)
        df.to_csv('multiTokenHistory.csv', index=False)
        return df
    else:
        df=pd.read_csv('multiTokenHistory.csv')
        return df

def TradeLog():
    if not os.path.exists('TradeLog.csv'):
        # Create a DataFrame with the desired structure
        data = {
            'token': [],
            'type': [],
            'datetime': [],
            'opprice': [],
            'amount': [],
            'result':[]
        }
        df = pd.DataFrame(data)
        df.to_csv('TradeLog.csv', index=False)
        return df
    else:
        df=pd.read_csv('TradeLog.csv')
        return df

def clear_tradeLog():
    try:
        os.remove("TradeLog.csv")
        print(" TradeLog.csv deleted successfully.")
    except FileNotFoundError:
        print("File TradeLog.csv not found.")
        pass
    except Exception as e:
        print(f"An error occurred: {e}")

def remove_single_TradeLog(token):
    df=TradeLog()
    index_to_remove = df[df['token'] == token].index[0]
    df = df.drop(index_to_remove)
    df.to_csv('TradeLog.csv', index=False)

def add_tradeLog(Ti, ttype, datetime, opprice,amount):
    dataframe=TradeLog()
    new_row = pd.DataFrame({
        'token': Ti,
        'type': ttype,
        'datetime': datetime,
        'opprice': opprice,
        'amount': amount,
        'result': ''
    }, index=[0])  # Ensure it's a single row DataFrame
    
    dataframe = pd.concat([dataframe, new_row], ignore_index=True)
    dataframe.to_csv('TradeLog.csv', index=False)
    
def update_cell_Tlog(token, column_name, new_value):
    df=TradeLog()
    row_index = df.index[df['token'] == token ].tolist()
    if not row_index:
        print(f"Indicator '{token}' not found.")
        return
    column_index = df.columns.get_loc(column_name)
    df.iloc[row_index[0], column_index] = new_value
    df.to_csv('TradeLog.csv', index=False)
    return True

def read_matching_TLog(token, column_name):
    df=TradeLog()
    row_index = df.index[df['token'] == token].tolist()
    if not row_index:
        print(f"Indicator '{token}' not found.")
        return
    column_index = df.columns.get_loc(column_name)
    cell_value = df.iloc[row_index[0], column_index]
    return cell_value


def clear_Token_History():
    try:
        os.remove("multiTokenHistory.csv")
        print(" multiTokenHistory.csv deleted successfully.")
    except FileNotFoundError:
        print("File multiTokenHistory.csv not found.")
        pass
    except Exception as e:
        print(f"An error occurred: {e}")
        pass

def filter_multi_trade(column_name, match_string):
    df=multiTokenHistory()
    if column_name not in df.columns:
        raise ValueError(f"Column '{column_name}' does not exist in the DataFrame.")
    # Filter the DataFrame
    filtered_df = df[df[column_name] == match_string]
    return filtered_df        

def add_token_history(sym, cprice, TCMF, TRSI, TZSCORE, TTREND):
    dataframe=multiTokenHistory()
    new_row = pd.DataFrame({
        'token': sym,
        'price': cprice,
        'CMF': TCMF,
        'RSI': TRSI,
        'Zscore': TZSCORE,
        'TREND': TTREND
    }, index=[0])  # Ensure it's a single row DataFrame
    
    dataframe = pd.concat([dataframe, new_row], ignore_index=True)
    dataframe.to_csv("multiTokenHistory.csv", index=False)    
########################database##############

###############Logic###################

def bot_limited_Tokens(dictionary, n):
    new_dict = {}
    count = 0
    for key, value in dictionary.items():
        if count < n:
            new_dict[key] = value
            count += 1
        else:
            break
    return new_dict
### we need to move it towards the average point that is showing up in wining situation
def Evaluate_Trades():
    TLog=TradeLog()
    for index,item in TLog.iterrows():
        the_token=item['token']
        trade_type=item['type']
        trade_result=item['result']
        tokenhistory=filter_multi_trade('token', the_token)
        if trade_result=="L":
            smallest_value = tokenhistory['price'].min()
            largest_value = tokenhistory['price'].max()
            row_with_smallest_value = tokenhistory.loc[tokenhistory['price'] == smallest_value]
            row_with_largest_value=tokenhistory.loc[tokenhistory['price'] == largest_value]
            both_above_or_below = same_side_check(row_with_largest_value, row_with_smallest_value, 0, len(tokenhistory))
            if both_above_or_below==False:
                fcompare={}
                trade_types=["GL","TL","GS","TS"]
                if row_with_smallest_value<row_with_largest_value:
                    pressurelist={}
                    for ttype in trade_types:
                        #opening side
                        range_rsi=ast.literal_eval(read_matching_table('nodes','RSI', ttype))
                        range_cmf=ast.literal_eval(read_matching_table('nodes','CMF', ttype))
                        range_zscore=ast.literal_eval(read_matching_table('nodes','ZSCORE', ttype))
                        TZSCORE=tokenhistory['ZSCORE'][row_with_smallest_value]
                        TCMF=tokenhistory['CMF'][row_with_smallest_value]
                        TRSI=tokenhistory['RSI'][row_with_smallest_value]
                        opening_intensity=eval_close(range_rsi[0],TRSI,range_cmf[0],TCMF,range_zscore[0],TZSCORE)
                        #closing side
                        TZSCORE=tokenhistory['ZSCORE'][row_with_largest_value]
                        TCMF=tokenhistory['CMF'][row_with_largest_value]
                        TRSI=tokenhistory['RSI'][row_with_largest_value]
                        close_intensity=eval_close(range_rsi[1],TRSI,range_cmf[1],TCMF,range_zscore[1],TZSCORE)
                        pressurelist[ttype]=(opening_intensity+close_intensity)/2
                    bestchoice=get_key_of_higher_number(pressurelist)
                    bias=float(read_matching_table('weights','bias', bestchoice))
                    if pressurelist[bestchoice]>bias:
                        fcompare['LONG']=[pressurelist[bestchoice],bestchoice]
                else:
                    pressurelist={}
                    for ttype in trade_types:
                        #opening side
                        range_rsi=ast.literal_eval(read_matching_table('nodes','RSI', ttype))
                        range_cmf=ast.literal_eval(read_matching_table('nodes','CMF', ttype))
                        range_zscore=ast.literal_eval(read_matching_table('nodes','ZSCORE', ttype))
                        TZSCORE=tokenhistory['ZSCORE'][row_with_largest_value]
                        TCMF=tokenhistory['CMF'][row_with_largest_value]
                        TRSI=tokenhistory['RSI'][row_with_largest_value]
                        opening_intensity=eval_close(range_rsi[0],TRSI,range_cmf[0],TCMF,range_zscore[0],TZSCORE)
                        #closing side
                        TZSCORE=tokenhistory['ZSCORE'][row_with_smallest_value]
                        TCMF=tokenhistory['CMF'][row_with_smallest_value]
                        TRSI=tokenhistory['RSI'][row_with_smallest_value]
                        close_intensity=eval_close(range_rsi[1],TRSI,range_cmf[1],TCMF,range_zscore[1],TZSCORE)
                        pressurelist[ttype]=round((opening_intensity+close_intensity)/2,3)
                    bestchoice= get_key_of_lower_number(pressurelist)
                    if pressurelist[bestchoice]>bias:
                        fcompare['SHORT']=[pressurelist[bestchoice],bestchoice]
            if fcompare['LONG'][0]<fcompare['SHORT'][0]:
                TZSCORE_o=tokenhistory['ZSCORE'][row_with_smallest_value]
                TCMF_o=tokenhistory['CMF'][row_with_smallest_value]
                TTREND_o=tokenhistory['TREND'][row_with_smallest_value]
                TRSI_o=tokenhistory['RSI'][row_with_smallest_value]
                TZSCORE_c=tokenhistory['ZSCORE'][row_with_largest_value]
                TCMF_c=tokenhistory['CMF'][row_with_largest_value]
                TTREND_c=tokenhistory['TREND'][row_with_largest_value]
                TRSI_c=tokenhistory['RSI'][row_with_largest_value]
                updatereflections(TZSCORE_o,TCMF_o,TRSI_o,TTREND_o,TZSCORE_c,TCMF_c,TTREND_c,TRSI_c,fcompare['LONG'][1])
                update_weights(trade_type)
            else:
                TZSCORE_c=tokenhistory['ZSCORE'][row_with_smallest_value]
                TCMF_c=tokenhistory['CMF'][row_with_smallest_value]
                TTREND_c=tokenhistory['TREND'][row_with_smallest_value]
                TRSI_c=tokenhistory['RSI'][row_with_smallest_value]
                TZSCORE_o=tokenhistory['ZSCORE'][row_with_largest_value]
                TCMF_o=tokenhistory['CMF'][row_with_largest_value]
                TTREND_o=tokenhistory['TREND'][row_with_largest_value]
                TRSI_o=tokenhistory['RSI'][row_with_largest_value]
                updatereflections(TZSCORE_o,TCMF_o,TRSI_o,TTREND_o,TZSCORE_c,TCMF_c,TTREND_c,TRSI_c,fcompare['SHORT'][1])
                update_weights(trade_type)
               
def running_average(previous_avg, new_number, total_items):
    if total_items == 0:
        return new_number
    else:
        return (previous_avg * total_items + new_number) / (total_items + 1)  
             
def updatereflections(TZSCORE_o,TCMF_o,TRSI_o,TTREND_o,TZSCORE_c,TCMF_c,TTREND_c,TRSI_c,ttype):
    range_rsi=ast.literal_eval(read_matching_table('relfections','RSI', ttype))
    range_cmf=ast.literal_eval(read_matching_table('reflections','CMF', ttype))
    trend=ast.literal_eval(read_matching_table('reflections','TREND', ttype))
    range_zscore=ast.literal_eval(read_matching_table('reflections','ZSCORE', ttype))
    TNUM=ast.literal_eval(read_matching_table('reflections','TNUM', ttype))
    range_rsi=[running_average(range_rsi[0], TRSI_o, TNUM),running_average(range_rsi[1], TRSI_c, TNUM)]
    range_cmf=[running_average(range_cmf[0], TCMF_o, TNUM),running_average(range_cmf[1], TCMF_c, TNUM)]
    range_zscore=[running_average(range_zscore[0], TZSCORE_o, TNUM),running_average(range_zscore[1], TZSCORE_c, TNUM)]
    trend=[running_average(trend[0], TTREND_o, TNUM),running_average(trend[1], TTREND_c, TNUM)]
    update_cell_table('reflections','RSI', ttype, range_rsi)
    update_cell_table('reflections','ZSCORE', ttype, range_zscore)
    update_cell_table('reflections','CMF', ttype, range_cmf)
    update_cell_table('reflections','TREND', ttype, trend)
         
def range_intensity_scaled(range_list, number, max_distance=20):
    # Unpack the range
    start, end = range_list
    
    # Check if the number is within the range
    if start <= number <= end:
        return False
    else:
        # Calculate the distance to the closest range boundary
        distance_to_start = abs(start - number)
        distance_to_end = abs(end - number)
        min_distance = min(distance_to_start, distance_to_end)
        
        # Scale the distance to a value between 0 and 1
        # Ensure that the maximum distance caps at 1 by using min function
        return min(min_distance / max_distance, 1)
    
def eval_close(range_rsi,TRSI,range_cmf,TCMF,range_zscore,TZSCORE):
    rsi_int=range_intensity_scaled(range_rsi,TRSI)
    cmf_int=range_intensity_scaled(range_cmf,TCMF)
    zscore_int=range_intensity_scaled(range_zscore,TZSCORE)
    if rsi_int != False and cmf_int != False and zscore_int != False:
        result = round((rsi_int + cmf_int + zscore_int) / 3 , 3)
        return result
    else:
        return False
        
def update_weights(trade_type):
    trend_w=ast.literal_eval(read_matching_table('weights','TREND', trade_type))
    cmf_w=ast.literal_eval(read_matching_table('weights','CMF',trade_type))
    zscore_w=ast.literal_eval(read_matching_table('weights','ZSCORE',trade_type))
    rsi_w=ast.literal_eval(read_matching_table('weights','RSI', trade_type))
    trend_w[0]=round(trend_w[0] - 0.1, 2)
    rsi_w[0]=round(rsi_w[0] - 0.1, 2)
    update_cell_table('weights','RSI', trade_type, rsi_w)
    update_cell_table('weights','TREND', trade_type, trend_w)
    cmf_w[0]=round(cmf_w[0] - 0.1, 2)
    update_cell_table('weights','CMF', trade_type, cmf_w)
    zscore_w[0]=round(zscore_w[0] - 0.1, 2)
    update_cell_table('weights','ZSCORE', trade_type, zscore_w)
    trend_w[1]=round(trend_w[1] - 0.1, 2)
    rsi_w[1]=round(rsi_w[1] - 0.1, 2)
    update_cell_table('weights','RSI', trade_type, rsi_w)
    update_cell_table('weights','TREND', trade_type, trend_w)
    cmf_w[1]=round(cmf_w[1] - 0.1, 2)
    update_cell_table('weights','CMF', trade_type, cmf_w)
    zscore_w[1]=round(zscore_w[1] - 0.1, 2)
    update_cell_table('weights','ZSCORE', trade_type, zscore_w)
    
def check_weights():
    pass
    
            
        
def unlearn():
    pass
    
        
######### Real Trading #############
def realtrade(bList,percentage,lvrg):
    pass

#############Logic####################
def simtrade(bList,BotLimit,simuwallet):
    client = Client(api_key, api_secret)
    for Ti,ttype in bList.items():
        candles = client.futures_continous_klines(pair=Ti, interval=globalInterval,ContractType='PERPETUAL')
        df = pd.DataFrame(candles)
        df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
        df['timestart'] = df['timestart'] / 1000
        df['timeend'] = df['timeend'] / 1000
        df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
        if ttype=="GL" or ttype=="TL":
            opprice = df['close'].iloc[-1]
            datetime=get_current_datetime_as_string()
            amount=simuwallet/BotLimit
            #add real Trade command here
            print("added:",Ti,ttype)
            add_tradeLog(Ti,ttype,datetime,opprice,amount)
        if ttype=="GS" or ttype=="TS":
            opprice = df['close'].iloc[-1]
            datetime=get_current_datetime_as_string()
            #add real Trade command here
            amount=simuwallet/BotLimit
            print("added:",Ti,ttype)
            add_tradeLog(Ti,ttype,datetime,opprice,amount)
    #sleep(900)
    while True:
        for Ti,ttype in bList.items():
            items_to_remove = []
            candles = client.futures_continous_klines(pair=Ti, interval=globalInterval,ContractType='PERPETUAL')
            df = pd.DataFrame(candles)
            df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
            df['timestart'] = df['timestart'] / 1000
            df['timeend'] = df['timeend'] / 1000
            df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
            TZSCORE=zscore(df)
            TCMF=CMF(df)
            TTREND=super_trend(df)
            TRSI=rsi(df)
            cprice = df['close'].iloc[-1]
            add_token_history(Ti, cprice,TCMF,TRSI,TZSCORE,TTREND)
            print("TokenHistoryadded:" ,Ti,cprice,TCMF,TRSI,TZSCORE,TTREND)
            print("CloseLayer:" ,Ti,CloseLayer(TRSI,TCMF,TTREND,TZSCORE,ttype))
            if CloseLayer(TRSI,TCMF,TTREND,TZSCORE,ttype):
                oprice=read_matching_TLog(Ti, 'opprice')
                if ttype=='GL' or ttype=='TL':
                    if oprice<cprice:
                        update_cell_Tlog(Ti, 'result', 'L')
                    else:
                        update_cell_Tlog(Ti, 'result', 'W')
                if ttype=='GS' or ttype=='TS':
                    if oprice>cprice:
                        update_cell_Tlog(Ti, 'result', 'L')
                    else:
                        update_cell_Tlog(Ti, 'result', 'W')
                print("trade closed : ", Ti)    
                items_to_remove.append(Ti)
                print("break from the loop")
                break
        for key in items_to_remove:
            del bList[key]
        if len(bList) == 0:
            break
        items_to_remove = []
        sleep(300)
    print("All Trades Done")
    return True
        


########trainer############
def main_trader(excludedlist,CurrencyType,BotLimit,lvrg):
    while True:
        TokenList = batchCollector(excludedlist,CurrencyType)
        print(TokenList)
        if len(TokenList)>0:
            botLimit_tokens=bot_limited_Tokens(TokenList, BotLimit)
            print(botLimit_tokens)
            result =simtrade(botLimit_tokens)
            if result==True:
                print("Now Evaluate")
                break
                Evaluate_Trades()
        sleep(900)

def simulated_trader(excludedlist,CurrencyType,BotLimit,simuwallet):
    retry=0
    while True:
        TokenList = batchCollector(excludedlist,CurrencyType)
        if len(TokenList)>0:
            botLimit_tokens=bot_limited_Tokens(TokenList,BotLimit)
            print(botLimit_tokens)
            result,newwallet =simtrade(botLimit_tokens,BotLimit,simuwallet)
            print("simuwallet amount :",newwallet)
            break
            if result==True:
                print("Now Evaluate")
                Evaluate_Trades()
                break
                check_weights()
                clear_Token_History()
                clear_tradeLog()
        else:
            if retry==4:
                unlearn()
            retry+=1
        print("sleeping waiting for next cycle")
        sleep(900)
            
clear_tradeLog()
clear_Token_History()    
print("Booting up... ")
excludedlist=['BTCUSDT','BTCDOMUSDT']
CurrencyType="USDT"
BotLimit=2
simuwallet=100
lvrg=2
#main_trader(excludedlist,CurrencyType,numBots,lvrg)
simulated_trader(excludedlist,CurrencyType,BotLimit,simuwallet)

    


