# -*- coding: utf-8 -*-
"""
Created on Mon Jul 22 06:58:25 2024

@author: azzy
"""
"""
how to test
1.geta tokens data
2. plot the graphs of indicators and combine them
3.look at the graph
4.write simple nerual network that predicts the graph training on the pervious data
5.plot the predictions and original
6. look at the graph
7.check if i want to store the weights or relearn everytime

building phase
1.find indicator that can show movement in graphs of specfic time interval (ADX,Zscore)
2.get the top moving tokens and arrange in descending order
3.preform regression or whatever the method is to predicto 50/50
4.arrange the tokens based on the longest time spent on either side of the 50/50
5.trade with the tokens arranged in ascending order
6.start traded
7.(this is looping) continue to predict and learn from the latest incoming values
8.close the trade
9.rinse and repeat
"""
from keys import *
# importing keys
import multiprocessing
import pandas as pd
import numpy as np #computing multidimensionla arrays
from datetime import datetime
from time import sleep
from binance.client import Client
from binance import *
from binance.enums import *
import math
import pandas_ta as ta
import operator
import os
import sys
import ast
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import accuracy_score
from scipy.signal import find_peaks
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
globalInterval=Client.KLINE_INTERVAL_15MINUTE
########close/open trades###########
def Lsafe(client,Seed,mrgType,lvrg):
    try:
        client.futures_change_leverage(symbol=Seed,leverage=lvrg)
        client.futures_change_margin_type(symbol=Seed,marginType=mrgType)
    except:
        return
    
#Precession
def get_current_datetime_as_string():
    current_datetime = datetime.now()
    return current_datetime.strftime("%Y-%m-%d %H:%M:%S")

def truncate(number, precision):
    factor = 10.0 ** precision
    return int(number * factor) / factor

def LongOrder(client, Seed, precision, numBots, lvrg):
    balance = client.futures_account_balance()
    bal = None
    
    for wc in balance:
        if wc["asset"] == 'USDT':
            bal = float(wc["balance"])
            break

    if bal is None:
        return "No USDT balance found"

    percent = 0.9 / numBots  # Calculate the percentage of balance to use for each bot

    price = float(client.futures_mark_price(symbol=Seed)["markPrice"])
    maxl = (bal * percent) * lvrg
    maxq = maxl / price
    q = truncate(maxq, precision)

    try:
        result=client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_BUY, quantity=str(q))
        if result['orderId']:
            return str(q)
        else:
            return 'null'
    except:
        return "null"

def ShortOrder(client, Seed, precision, numBots, lvrg):
    balance = client.futures_account_balance()
    bal = None
    
    for wc in balance:
        if wc["asset"] == 'USDT':
            bal = float(wc["balance"])
            break

    if bal is None:
        return "No USDT balance found"

    percent = 0.9 / numBots  # Calculate the percentage of balance to use for each bot

    price = float(client.futures_mark_price(symbol=Seed)["markPrice"])
    maxl = (bal * percent) * lvrg
    maxq = maxl / price
    q = truncate(maxq, precision)

    try:
        result=client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_SELL, quantity=str(q))
        if result['orderId']:
            return str(q)
        else:
            return 'null'
    except:
        return "null"

def closeLong(client, p, Seed):
    try:
        client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_SELL, quantity=p, reduceOnly='true')
        return f"Closed long position with quantity {p}"
    except:
        return "null"

def closeShort(client, p, Seed):
    try:
        client.futures_create_order(symbol=Seed, type=ORDER_TYPE_MARKET, side=SIDE_BUY, quantity=p, reduceOnly='true')
        return f"Closed short position with quantity {p}"
    except:
        return "null"
    
def TradeLog():
    if not os.path.exists('TradeLog.csv'):
        # Create a DataFrame with the desired structure
        data = {
            'token': [],
            'datetime': [],
            'opprice': [],
            'result':[],
            'status': [],
            'EXP':[],
            'CT':[]
        }
        df = pd.DataFrame(data)
        df.to_csv('TradeLog.csv', index=False)
        return df
    else:
        df=pd.read_csv('TradeLog.csv')
        return df

def clear_tradeLog():
    try:
        os.remove("TradeLog.csv")
        print(" TradeLog.csv deleted successfully.")
    except FileNotFoundError:
        print("File TradeLog.csv not found.")
        pass
    except Exception as e:
        print(f"An error occurred: {e}")

def add_tradeLog(Ti,datetime, opprice,result,amount,status,EXP,CT):
    dataframe=TradeLog()
    new_row = pd.DataFrame({
        'token': Ti,
        'datetime': datetime,
        'opprice': opprice,
        'amount': amount,
        'result': result,
        'status': status,
        'EXP':EXP,
        'CT':CT
    }, index=[0])  # Ensure it's a single row DataFrame
    
    dataframe = pd.concat([dataframe, new_row], ignore_index=True)
    dataframe.to_csv('TradeLog.csv', index=False)
    
def update_cell_Tlog(token, column_name, new_value):
    df=TradeLog()
    row_index = df.index[df['token'] == token ].tolist()
    if not row_index:
        print(f"Indicator '{token}' not found.")
        return
    column_index = df.columns.get_loc(column_name)
    df.iloc[row_index[0], column_index] = new_value
    df.to_csv('TradeLog.csv', index=False)
    return True

def read_matching_TLog(token, column_name):
    df=TradeLog()
    row_index = df.index[df['token'] == token].tolist()
    if not row_index:
        print(f"Indicator '{token}' not found.")
        return
    column_index = df.columns.get_loc(column_name)
    cell_value = df.iloc[row_index[0], column_index]
    return cell_value
#########################neural stuff########################


# Activation function and its derivative
def sigmoid(x):
    # Clip values to avoid overflow in exp
    x = np.clip(x, -500, 500)
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# Initialize weights with better distribution
def initialize_weights(input_size, hidden_size, output_size):
    weights = {
        'W1': np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size),
        'b1': np.zeros((1, hidden_size)),
        'W2': np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size),
        'b2': np.zeros((1, output_size))
    }
    return weights

# Load weights if they exist, otherwise initialize them
def load_or_initialize_weights(filename, input_size, hidden_size, output_size):
    if os.path.exists(filename):
        return load_weights(filename)
    else:
        return initialize_weights(input_size, hidden_size, output_size)

# Forward pass
def forward_pass(X, weights):
    z1 = np.dot(X, weights['W1']) + weights['b1']
    a1 = sigmoid(z1)
    z2 = np.dot(a1, weights['W2']) + weights['b2']
    output = z2  # No activation for output layer (regression problem)
    return z1, a1, z2, output

# Backward pass
def backward_pass(X, y, z1, a1, z2, output, weights, learning_rate):
    m = y.shape[0]
    d_output = output - y
    d_W2 = np.dot(a1.T, d_output) / m
    d_b2 = np.sum(d_output, axis=0, keepdims=True) / m
    d_a1 = np.dot(d_output, weights['W2'].T)
    d_z1 = d_a1 * sigmoid_derivative(a1)
    d_W1 = np.dot(X.T, d_z1) / m
    d_b1 = np.sum(d_z1, axis=0, keepdims=True) / m

    weights['W1'] -= learning_rate * d_W1
    weights['b1'] -= learning_rate * d_b1
    weights['W2'] -= learning_rate * d_W2
    weights['b2'] -= learning_rate * d_b2

    return weights

# Training function with incremental learning
def train_network(series):
    hidden_size = 20
    learning_rate = 0.01
    epochs = 1000
    weight_file = 'weights.npz'
    input_size = 1
    output_size = 1

    series = np.array(series).reshape(-1, 1)
    X = series[:-1]
    y = series[1:]

    weights = load_or_initialize_weights(weight_file, input_size, hidden_size, output_size)

    for epoch in range(epochs):
        z1, a1, z2, output = forward_pass(X, weights)
        weights = backward_pass(X, y, z1, a1, z2, output, weights, learning_rate)

        if epoch % 100 == 0:
            loss = np.mean((output - y) ** 2)
            print(f'Epoch {epoch}, Loss: {loss}')

    save_weights(weights, weight_file)
    return weights

# Save weights
def save_weights(weights, filename):
    np.savez(filename, W1=weights['W1'], b1=weights['b1'], W2=weights['W2'], b2=weights['b2'])

# Load weights
def load_weights(filename):
    data = np.load(filename)
    weights = {
        'W1': data['W1'],
        'b1': data['b1'],
        'W2': data['W2'],
        'b2': data['b2']
    }
    return weights

# Predict function
def predict_next(series):
    weights = load_weights('weights.npz')
    series = np.array(series).reshape(-1, 1)
    X = series[-1].reshape(1, -1)
    _, _, _, output = forward_pass(X, weights)
    return output[0, 0]

def count_consecutive_values(series):
    counts = []
    count = 1
    
    for i in range(1, len(series)):
        if (series.iloc[i] > 0 and series.iloc[i-1] > 0) or (series.iloc[i] <= 0 and series.iloc[i-1] <= 0):
            count += 1
        else:
            if series.iloc[i-1] > 0:
                counts.append(count)
            else:
                counts.append(-count)
            count = 1
    
    # Append the last count
    if series.iloc[-1] > 0:
        counts.append(count)
    else:
        counts.append(-count)
    
    return pd.Series(counts)
#################### Get token info #########################

def batchCollector(excludedlist,CurrencyType):
    client = Client(api_key, api_secret)
    exInfo=client.futures_exchange_info()
    tokenInf,sinf=FindNewToken(client,exInfo,excludedlist,CurrencyType)
    Ftoken_list=OpenLayer(tokenInf)
    return Ftoken_list,sinf

def TokenInfo(client,sym,CurrencyType):
    try:
        candles = client.futures_continous_klines(pair=sym, interval=globalInterval,ContractType='PERPETUAL')
        df = pd.DataFrame(candles)
        df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
        df['timestart'] = df['timestart'] / 1000
        df['timeend'] = df['timeend'] / 1000
        df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
        return df
    except Exception as e:
        #TokenInfo error Removed from Market or not added yet
        print("TokenInfo error Removed from Market or not added yet",e)

def FindNewToken(client,exInfo,excludedlist,CurrencyType):
    symInfo={}
    tokenInfo={}
    for symbol in exInfo["symbols"]:
        if symbol["contractType"]=="PERPETUAL" and symbol["symbol"] not in excludedlist and CurrencyType in symbol["symbol"] and symbol["status"]=="TRADING":
            symInfo[symbol["symbol"]]=symbol["quantityPrecision"]
    x=0
    for key,values in symInfo.items():
        result=TokenInfo(client,key,CurrencyType)
        tokenInfo[key]=result
        if x==30:
            print("30%")
        if x==80:
            print("80%")
        if x==130:
            print("99%")
        x+=1
    print('100%')            
    return tokenInfo,symInfo

def OpenLayer(TokenInfo):
    ranked_result={}
    for Ti,df in TokenInfo.items():
        try:        
            cmf_series=CMF(df)
            rsi_series=rsi(df)
            macd_series=MACD(df)
            # Combine the normalized and smoothed series
            series = (cmf_series + rsi_series + macd_series) / 3
            series = count_consecutive_values(series)
            # Train the network
            train_network(series)
        except Exception as e:
            #TokenInfo error Removed from Market or not added yet
            print("Trainloop error",e)
            continue   
    for Ti,df in TokenInfo.items():
        try:        
            cmf_series=CMF(df)
            rsi_series=rsi(df)
            macd_series=MACD(df)
            # Combine the normalized and smoothed series
            series = (cmf_series + rsi_series + macd_series) / 3
            series = count_consecutive_values(series)
            # Predict the next element
            next_element = round(predict_next(series),2)
            if next_element<0:
                element=abs(next_element)
                ranked_result[Ti]=[element,'FS']
            if next_element>0:
                element=abs(next_element)
                ranked_result[Ti]=[element,'FL']
        except Exception as e:
            #TokenInfo error Removed from Market or not added yet
            print("predictloop error",e)
            continue   
    # Sort the keys based on the first element of the list in descending order
    sorted_keys = sorted(ranked_result.keys(), key=lambda x: ranked_result[x][0], reverse=True)
    # Reorganize the dictionary using the sorted keys
    sorted_ranked_result = {key: ranked_result[key] for key in sorted_keys}
    return sorted_ranked_result

#################### Get token info #########################

############# Indicators #############

def CMF(data):
    period = 20
    mf = ((data['close'] - data['low']) - (data['high'] - data['close'])) / (data['high'] - data['low'])
    mfv = mf * data['volume']
    cmf_values = mfv.rolling(period).sum() / data['volume'].rolling(period).sum()
    
    # Initialize the full index
    full_index = np.arange(len(data))
    
    # Fill NaN values using linear regression
    original_series = cmf_values
    filled_series = original_series.reindex(full_index)

    # Indices of non-NaN values
    not_nan_indices = np.where(~np.isnan(filled_series))[0]
    # Indices of NaN values
    nan_indices = np.where(np.isnan(filled_series))[0]

    # Perform linear regression if there are NaN values
    if len(nan_indices) > 0:
        reg = LinearRegression()
        if len(not_nan_indices) > 1:  # Only fit if there are enough points
            reg.fit(not_nan_indices.reshape(-1, 1), filled_series.dropna().values)
            # Predict NaN values
            filled_series[nan_indices] = reg.predict(nan_indices.reshape(-1, 1))
        
        # If filled_series is still NaN at index 0, fill it with the first non-NaN value
        if np.isnan(filled_series[0]):
            filled_series[0] = filled_series.dropna().iloc[0]

    normalized_series = 2 * (filled_series - filled_series.min()) / (filled_series.max() - filled_series.min()) - 1
    return normalized_series


def rsi(dataset, period=14):
    # Calculate daily returns
    delta = dataset['close'].diff()
    
    # Separate positive and negative gains/losses
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # Calculate average gain and loss
    avg_gain = gain.rolling(window=period, min_periods=1).mean()
    avg_loss = loss.rolling(window=period, min_periods=1).mean()
    
    # Calculate the Relative Strength (RS)
    rs = avg_gain / avg_loss
    
    # Calculate the RSI
    rsi = 100 - (100 / (1 + rs))
    normalized_rsi = 2 * (rsi - 50) / 100
    
    # Fill NaN values using linear regression
    original_series = normalized_rsi
    full_index = np.arange(len(dataset))
    filled_series = original_series.reindex(full_index)

    # Indices of non-NaN values
    not_nan_indices = np.where(~np.isnan(filled_series))[0]
    # Indices of NaN values
    nan_indices = np.where(np.isnan(filled_series))[0]

    # Perform linear regression if there are NaN values
    if len(nan_indices) > 0:
        reg = LinearRegression()
        if len(not_nan_indices) > 1:  # Only fit if there are enough points
            reg.fit(not_nan_indices.reshape(-1, 1), filled_series.dropna().values)
            # Predict NaN values
            filled_series[nan_indices] = reg.predict(nan_indices.reshape(-1, 1))
        
        # If filled_series is still NaN at index 0, fill it with the first non-NaN value
        if np.isnan(filled_series[0]):
            filled_series[0] = filled_series.dropna().iloc[0]

    normalized_series = 2 * (filled_series - filled_series.min()) / (filled_series.max() - filled_series.min()) - 1
    return normalized_series

def calculate_ema(series, period):
    return series.ewm(span=period, adjust=False).mean()

def MACD(dataset, short_period=12, long_period=26, signal_period=9):
    # Calculate the short-term EMA (12-day EMA)
    short_ema = calculate_ema(dataset['close'], short_period)
    
    # Calculate the long-term EMA (26-day EMA)
    long_ema = calculate_ema(dataset['close'], long_period)
    
    # Calculate the MACD line
    macd_line = short_ema - long_ema
    
    # Calculate the Signal line (9-day EMA of the MACD line)
    signal_line = calculate_ema(macd_line, signal_period)
    
    # Calculate the MACD Histogram
    macd_histogram = macd_line - signal_line
    
    # Normalize the MACD Histogram to a range from -100 to 100
    max_abs_histogram = macd_histogram.abs().max()
    normalized_histogram = (macd_histogram / max_abs_histogram) * 100
    
    # Fill NaN values using linear regression
    original_series = normalized_histogram
    full_index = np.arange(len(dataset))
    filled_series = original_series.reindex(full_index)

    # Indices of non-NaN values
    not_nan_indices = np.where(~np.isnan(filled_series))[0]
    # Indices of NaN values
    nan_indices = np.where(np.isnan(filled_series))[0]

    # Perform linear regression if there are NaN values
    if len(nan_indices) > 0:
        reg = LinearRegression()
        if len(not_nan_indices) > 1:  # Only fit if there are enough points
            reg.fit(not_nan_indices.reshape(-1, 1), filled_series.dropna().values)
            # Predict NaN values
            filled_series[nan_indices] = reg.predict(nan_indices.reshape(-1, 1))
        
        # If filled_series is still NaN at index 0, fill it with the first non-NaN value
        if np.isnan(filled_series[0]):
            filled_series[0] = filled_series.dropna().iloc[0]

    normalized_series = 2 * (filled_series - filled_series.min()) / (filled_series.max() - filled_series.min()) - 1
    return normalized_series

def z_score(series):
    return (series - series.mean()) / series.std()

def moving_average(series, window=14):
    return series.rolling(window=window, min_periods=1).mean()

def all_w_or_l(column_name, df):
    # Check if the column exists in the DataFrame
    if column_name not in df.columns:
        raise ValueError(f"Column '{column_name}' does not exist in the DataFrame.")
    
    # Check if all values in the column are either 'W' or 'L'
    if (df[column_name].isin(['W', 'L'])).all():
        return True
    else:
        return False
    
############# Indicators #############    
########close/open trades########### add_tradeLog(Ti,datetime, opprice,result,amount,status,EXP)
def Rtrade(bList,BotLimit,lvrg,tinfo,mode):
    client = Client(api_key, api_secret)
    mrgType="ISOLATED"
    x=0
    for Ti,ttype in bList.items():
        Lsafe(client, Ti, mrgType, lvrg)
        candles = client.futures_continous_klines(pair=Ti, interval=globalInterval,ContractType='PERPETUAL')
        df = pd.DataFrame(candles)
        df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
        df['timestart'] = df['timestart'] / 1000
        df['timeend'] = df['timeend'] / 1000
        df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
        if ttype[1]=="FL":
            opprice = df['close'].iloc[-1]
            datetime=get_current_datetime_as_string()
            if mode=='R':
                p=LongOrder(client,Ti,tinfo[Ti],BotLimit,lvrg)
                if p!="null" and p!='':    
                    print("added:",Ti,ttype)
                    add_tradeLog(Ti,datetime,opprice,'A',p,ttype[1],ttype[0],0)
                    x+=1
            else:
                print("added:",Ti,ttype)
                add_tradeLog(Ti,datetime,opprice,'A','nan',ttype[1],ttype[0],0)
                x+=1
        if  ttype[1]=="FS":
            opprice = df['close'].iloc[-1]
            datetime=get_current_datetime_as_string()
            if mode=='R':
                p=ShortOrder(client,Ti,tinfo[Ti],BotLimit,lvrg)
                if p!="null" and p!='':
                    print("added:",Ti,ttype)
                    add_tradeLog(Ti,datetime,opprice,'A',p,ttype[1],ttype[0],0)
                    x+=1
            else:
                print("added:",Ti,ttype)
                add_tradeLog(Ti,datetime,opprice,'A','nan',ttype[1],ttype[0],0)
                x+=1
        if x>=BotLimit:
            break
        sleep(5)
    while True:
        TLog=TradeLog()
        for x in range(len(TLog)):
            status=TLog.iloc[x]['status']
            svresult=TLog.iloc[x]['result']
            Ti=TLog.iloc[x]['token']
            amount=read_matching_TLog(Ti, 'amount')
            oprice=read_matching_TLog(Ti, 'opprice')
            CT=read_matching_TLog(Ti, 'CT')
            EXP=read_matching_TLog(Ti, 'EXP')
            if svresult!='W' and svresult!='L':
                if CT>EXP:
                    candles = client.futures_continous_klines(pair=Ti, interval=globalInterval,ContractType='PERPETUAL')
                    df = pd.DataFrame(candles)
                    df.columns = ['timestart', 'open', 'high', 'low', 'close', 'volume', 'timeend', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'unused_field']
                    df['timestart'] = df['timestart'] / 1000
                    df['timeend'] = df['timeend'] / 1000
                    df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']] = df[['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].astype(float)
                    cmf_series=CMF(df)
                    rsi_series=rsi(df)
                    macd_series=MACD(df)
                    cprice = df['close'].iloc[-1]
                    # Combine the normalized and smoothed series
                    series = (cmf_series + rsi_series + macd_series) / 3
                    series = count_consecutive_values(series)
                    # Train the network
                    train_network(series)
                    # Predict the next element
                    next_element = round(predict_next(series),2)
                    if status=='FS':
                        if next_element>0:
                            if oprice>cprice:
                                if mode=='R':
                                    closeShort(client,amount,Ti)
                                update_cell_Tlog(Ti, 'result', 'W')
                                print("trade closed : ", Ti)
                                break
                            else:
                                update_cell_Tlog(Ti, 'result', 'L')
                                print("trade closed : ", Ti)
                                break
                        else:
                            EXP= next_element+CT
                            update_cell_Tlog(Ti, 'EXP', EXP)
                    if status=='FL':
                        if next_element<0:
                            if oprice<cprice:
                                if mode=='R':
                                    closeLong(client,amount,Ti)
                                update_cell_Tlog(Ti, 'result', 'W')
                                print("trade closed : ", Ti)
                                break
                            else:
                                update_cell_Tlog(Ti, 'result', 'L')
                                print("trade closed : ", Ti)
                                break
                        else:
                            EXP= next_element+CT
                            update_cell_Tlog(Ti, 'EXP', EXP)
                else:
                    CT+=1
                    update_cell_Tlog(Ti, 'CT', CT)
        TLog=TradeLog()
        if all_w_or_l('result', TLog):
            print("All Trades Done")
            return True
        sleep(900)
    print("All Trades Done")
    return True
########trainer############
def MAIN_TRADER(excludedlist,CurrencyType,BotLimit,lvrg,initial,mode):
    client = Client(api_key, api_secret)
    while True:
        balance = client.futures_account_balance()
        bal = None
        for wc in balance:
            if wc["asset"] == 'USDT':
                bal = float(wc["balance"])
        if bal > initial:
            amnt = bal - initial
            client.futures_account_transfer(asset='USDT', amount=amnt, Type=2)
            print("Profit Transfer:", amnt)
        if bal > 100:
            BotLimit=4
        if bal > 500:
            BotLimit=8
        if bal > 900:
            BotLimit=10
        TokenList,tinfo = batchCollector(excludedlist,CurrencyType)
        print(TokenList)
        if len(TokenList)>0:
            Rtrade(TokenList,BotLimit,lvrg,tinfo,mode)
        clear_tradeLog()
        print("sleeping waiting for next cycle")
        sleep(1800)
clear_tradeLog()
BotLimit=2
mode='S'
print("Booting up... ")
excludedlist=['BTCUSDT','BTCDOMUSDT','USDCUSDT','ETHUSDT','XEMUSDT']
CurrencyType="USDT"
lvrg=2
initial_amt=1000
MAIN_TRADER(excludedlist,CurrencyType,BotLimit,lvrg,initial_amt,mode)
